Title: Eye saccading movements by frame contents

Brief Description: 
It isn't surely known what manner of thinking and methodology people experience when they take a gander at and examine pictures. 
Our decision to look at specific areas in a picture and afterward hop, or saccade, to different areas may be propelled by either the organization of the picture itself or rather by brain signals autonomous of the picture.
In this project, we wish to detect features in images that motivate changes in the eye of the viewer.  

Full Description:

Our decision to look at specific areas in a picture and afterward hop, or saccade, to different areas might be persuaded by either the creation of the picture itself or rather by cerebrum signals independent of the picture. In this project, we  endeavor to identify highlights in pictures that propel hops in the area of a subject's look. At the point when people take a gander at a picture they either focus on a point or moving article, or their eyes will saccade to another point, which means they will take a quick leap toward another area in the picture. Existing works on this topic address this inquiry generally center around obsession focuses rather than saccades, foreseeing which group of points eyes will hook upon. Our objective for our project varies in that we attempt to foresee, given a current point of obsession in a frame of a video, where the eyes will saccade to and next focus upon in the following video frames. Also, many existing works on this have certain limitations, like just working with high contrast pictures and just thinking about simple features, similar to complexity and orientation of an image. We plan to work by passing video frames edited around a main issue of obsession into a convolutional neural network. The network yields a dissemination of probabilities allocated to a 4x4 framework comparing to segments of the picture, showing the probability of the watchers gaze saccading to that position on the off chance that they are focusing upon the given point currently. 
