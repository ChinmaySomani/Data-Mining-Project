{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNUvHwfIprsMt+O4t/xYTSB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChinmaySomani/Data-Mining-Project/blob/master/Main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUhC0i36fdp7",
        "outputId": "6a2fc0a9-d201-4abb-b379-cd15099469f5"
      },
      "source": [
        "!git clone https://github.com/ChinmaySomani/Data-Mining-Project"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Data-Mining-Project'...\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 2783 (delta 2), reused 19 (delta 2), pack-reused 2764\u001b[K\n",
            "Receiving objects: 100% (2783/2783), 814.91 MiB | 33.64 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n",
            "Checking out files: 100% (2764/2764), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MnJfyL3fv3n"
      },
      "source": [
        "import numpy as np\n",
        "def data_into_lists(filename):\n",
        "    DataList = []\n",
        "    with open(filename, 'r') as file:\n",
        "        for data in file:\n",
        "            data = data.rstrip('\\n')\n",
        "            dataEntry = data.split(' ')\n",
        "            #print(dataEntry)\n",
        "            if dataEntry[0][0] != '#' and len(dataEntry) == 4 and float(dataEntry[3]) == 1:\n",
        "                lists = []\n",
        "                for x in range(0,3):\n",
        "                    lists.append(dataEntry[x])\n",
        "                DataList.append(lists)\n",
        "    return DataList\n",
        "#coords = data_into_lists('Git/Data/gaze/natural_movies_gaze/AAF_beach.coord') \n",
        "#coord_matrix = np.array(coords)\n",
        "#coords[0]\n",
        "def load_file(filename, data_name):\n",
        "    coords = data_into_lists(filename)\n",
        "    coord_matrix = np.array(coords)\n",
        "    #returns a numpy array of [timestamp, x_loc, y_loc] using coord files \n",
        "    return data_name, coord_matrix"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DH_-L_Q6Txzx"
      },
      "source": [
        "#%run data_reader.ipynb\n",
        "import numpy as np\n",
        "import scipy.spatial.distance as distance\n",
        "interval_time = 8000\n",
        "start_threshold = 0.002\n",
        "end_threshold = 0.001\n",
        "def closestTime(coordMatrix, timestamp):\n",
        "    closeTime = 0\n",
        "    loca = ()\n",
        "    minim = 15000\n",
        "    for coord_matrix in coordMatrix:\n",
        "        if(abs(int(coord_matrix[0]) - timestamp) < minim):\n",
        "            minim = abs(int(coord_matrix[0]) - timestamp)\n",
        "            closeTime = int(coord_matrix[0])\n",
        "            loca = (int(float(coord_matrix[1])), int(float(coord_matrix[2])))\n",
        "    return closeTime, loca\n",
        "\n",
        "def intervals(filename):\n",
        "    name, coords = load_file(filename, 'test')\n",
        "    interval = []\n",
        "    start_time = int(coords[0][0])\n",
        "    #last = coords[-1][0]\n",
        "    while start_time < int(coords[-1][0])-1:\n",
        "        final_start_time, start_loc = closestTime(coords, start_time)\n",
        "        end_time = start_time + interval_time\n",
        "        final_end_time, end_loc = closestTime(coords, end_time)\n",
        "        if(final_end_time == final_start_time):\n",
        "            end_time = final_start_time + 10000\n",
        "            final_end_time, end_loc = closestTime(coords, end_time)\n",
        "        interval.append((start_loc, end_loc, int(final_end_time - final_start_time), final_start_time))\n",
        "        start_time = start_time + (interval_time/2)\n",
        "    inteval = np.array(interval, dtype=object)\n",
        "    return interval\n",
        "\n",
        "def velocities(interval):\n",
        "    velocity = []\n",
        "    for inter in interval:\n",
        "        if(len(inter) and inter[2] and len(inter[0]) and len(inter[1])):\n",
        "            #print(inter)\n",
        "            #if(inter[2] != 0):\n",
        "            dist = pow((pow(inter[0][0] - inter[1][0],2) + pow(inter[0][1] - inter[1][1],2)), 1/2)\n",
        "            vel = int(dist)/inter[2]\n",
        "            velocity.append(vel)\n",
        "    velocity = np.array(velocity)\n",
        "    return velocity\n",
        "\n",
        "def extract_saccades(velocity, interval):  #videopath\n",
        "    saccade = False\n",
        "    data = []\n",
        "    start_location = None\n",
        "    for i in range(0, len(velocity)-1):\n",
        "        acc = abs(velocity[i+1] - velocity[i])\n",
        "        if saccade == False:\n",
        "            if acc >= start_threshold:\n",
        "                saccade = True\n",
        "                start_location = interval[i][0]\n",
        "                timestamp = interval[i][3]\n",
        "        else:\n",
        "            if acc <= end_threshold:\n",
        "                saccade = False\n",
        "                label = interval[i][1]\n",
        "                data.append((start_location, label, timestamp)) #videopath\n",
        "                start_location = None\n",
        "    #return ((start_loc, label, timeframe))            \n",
        "    return data\n",
        "\n",
        "    #interval1 = intervals('Git/Data/gaze/natural_movies_gaze/AAF_beach.coord')\n",
        "#vel = velocities(interval1)\n",
        "#data = extract_saccades(vel, interval1)\n",
        "#print(len(data))\n",
        "#print(len(vel))\n",
        "#print(data[0])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbyCURa_2BE3",
        "outputId": "bd945a39-dc23-440d-a5df-139bcd0caa1b"
      },
      "source": [
        "!pip install sk-video"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sk-video\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/3f/ce848b8b2062ad1ccf1449094a740c775f6c761339f411e44f1e090f23a7/sk_video-1.1.10-py2.py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 10.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from sk-video) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from sk-video) (1.18.5)\n",
            "Installing collected packages: sk-video\n",
            "Successfully installed sk-video-1.1.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZtGA3R0UIDf"
      },
      "source": [
        "\n",
        "import imageio\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import skvideo.io\n",
        "import cv2 \n",
        "import os\n",
        "\n",
        "def frameExtractor(filename, timestamp):\n",
        "    vid = cv2.VideoCapture(filename)\n",
        "    framePerSec = vid.get(cv2.CAP_PROP_FPS)\n",
        "    framePerSec = framePerSec/1000\n",
        "    frameNumber = 0\n",
        "    if timestamp >= 1 : \n",
        "        frameNumber = int(framePerSec * timestamp) - 1\n",
        "    return frameNumber\n",
        "\n",
        "def getFrame(timestamp, x, y, videopath):\n",
        "    width = 1280\n",
        "    height = 720\n",
        "    videodata = skvideo.io.vread(videopath)\n",
        "    frameNum = frameExtractor(videopath, timestamp/1000)\n",
        "    frame = videodata[frameNum-1]\n",
        "    imageio.imsave('frame.jpg', frame)\n",
        "\n",
        "#def createDirectory(directory):\n",
        " #   import os\n",
        " #   #if directory is not present then make it\n",
        " #   if os.path.exists(os.path.dirname(directory)) == False :\n",
        " #       os.makedirs(os.path.dirname(directory))\n",
        "\n",
        "def tripleCrop(imagepath, coord):\n",
        "    #createDirectory(directory)\n",
        "    x, y = coord\n",
        "    cropDim = 32\n",
        "    for i in range(0,3):\n",
        "        im = Image.open(imagepath)\n",
        "        cropDim = cropDim*2 \n",
        "        leftCor = x - cropDim\n",
        "        rightCor = x + cropDim\n",
        "        upperCor = y - cropDim\n",
        "        lowerCor = y + cropDim\n",
        "        im = im.crop((leftCor, upperCor, rightCor, lowerCor))\n",
        "        im = im.resize((64, 64))\n",
        "        #path = directory + name + '_' + str(i) + '.png'\n",
        "        im.save('triplecroppedimage'+str(i)+'.jpg')\n",
        "\n",
        "def combineTripleCrop(entry):\n",
        "    #createDirectory('TrainingData')\n",
        "    crop0 = imageio.imread('triplecroppedimage0.jpg')\n",
        "    crop1 = imageio.imread('triplecroppedimage1.jpg')\n",
        "    crop2 = imageio.imread('triplecroppedimage2.jpg')\n",
        "    H = 64\n",
        "    W = 64*3\n",
        "    C = 3\n",
        "    triple = np.zeros((H,W,C), dtype=np.uint8)\n",
        "    triple[:, :W//3, :] += crop0\n",
        "    triple[:, W//3 : 2*W//3, :] += crop1\n",
        "    triple[:, 2*W//3:, :] += crop2\n",
        "    imageio.imsave('TrainingData/combine'+ str(entry) + '.jpg', triple)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zc9RxUOnUdK7"
      },
      "source": [
        "#%run data_reader.ipynb\n",
        "#%run Sacade_extractor.ipynb\n",
        "#%run VideoUtilites.ipynb\n",
        "import csv\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import imageio\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def maketraindata(file, video, filecount):\n",
        "  interval = intervals(file)\n",
        "  velocity = velocities(interval)\n",
        "  data = extract_saccades(velocity, interval)\n",
        "\n",
        "  data = np.array(data)\n",
        "  data.shape\n",
        "\n",
        "  w = csv.writer(open(\"labels.csv\", \"a\"))\n",
        "  entry = 0\n",
        "  for point, label, timestamp in data:\n",
        "    if timestamp and label and point :\n",
        "      x, y = point\n",
        "      getFrame(timestamp/1000, x, y, video)\n",
        "      tripleCrop('frame.jpg', point)\n",
        "   # combineTripleCrop(entry)\n",
        "\n",
        "\n",
        "      label_x, label_y = label\n",
        "      CropDim = 512//2\n",
        "      if label_y > y + CropDim:\n",
        "        label_y = y + CropDim\n",
        "      elif label_y < y - CropDim:\n",
        "        label_y = y - CropDim\n",
        "      if label_x > x + CropDim:\n",
        "        label_x = x + CropDim\n",
        "      elif label_x < x - CropDim:\n",
        "        label_x = x - CropDim\n",
        "    \n",
        "      label_y_LeftBigCrop = label_y - y + CropDim\n",
        "      label_x_LeftBigCrop = label_x - x + CropDim\n",
        "      label_x_LeftBigCrop /= 8\n",
        "      label_y_LeftBigCrop /= 8  \n",
        "      fx = round(label_x_LeftBigCrop)\n",
        "      fy = round(label_y_LeftBigCrop)\n",
        "      label = (fx, fy)\n",
        "      w.writerow([entry,'TrainingData/combine' + str(entry)+'.jpg', label[0], label[1]])\n",
        "\n",
        "      crop0 = imageio.imread('triplecroppedimage0.jpg')\n",
        "      crop1 = imageio.imread('triplecroppedimage1.jpg')\n",
        "      crop2 = imageio.imread('triplecroppedimage2.jpg')\n",
        "      H = 64\n",
        "      W = 64*3\n",
        "      C = 3\n",
        "      triple = np.zeros((H,W,C), dtype=np.uint8)\n",
        "      triple[:, :W//3, :] += crop0\n",
        "      triple[:, W//3 : 2*W//3, :] += crop1\n",
        "      triple[:, 2*W//3:, :] += crop2\n",
        "\n",
        "      if fx <= 16 :\n",
        "        if fy <= 16 :\n",
        "          imageio.imsave('TrainingData/0/combine'+ str(filecount) + 'o' + str(entry) + '.jpg', triple)\n",
        "        if fy > 16 and fy <= 32 :\n",
        "          imageio.imsave('TrainingData/1/combine'+ str(filecount) + 'o' + str(entry) + '.jpg', triple)\n",
        "        if fy > 32 and fy <= 48 :\n",
        "          imageio.imsave('TrainingData/2/combine'+ str(filecount) + 'o' + str(entry) + '.jpg', triple)\n",
        "        if fy > 48 and fy <= 64 :\n",
        "          imageio.imsave('TrainingData/3/combine'+ str(filecount) + 'o' + str(entry) + '.jpg', triple)\n",
        "      if fx > 16 and fx <=32 :\n",
        "        if fy <= 16 :\n",
        "          imageio.imsave('TrainingData/4/combine'+ str(filecount) + 'o' + str(entry) + '.jpg', triple)\n",
        "        if fy > 16 and fy <= 32 :\n",
        "          imageio.imsave('TrainingData/5/combine'+ str(filecount) + 'o' + str(entry) + '.jpg', triple)\n",
        "        if fy > 32 and fy <= 48 :\n",
        "          imageio.imsave('TrainingData/6/combine'+ str(filecount) + 'o' + str(entry) + '.jpg', triple)\n",
        "        if fy > 48 and fy <= 64 :\n",
        "          imageio.imsave('TrainingData/7/combine'+ str(filecount) + 'o' + str(entry) + '.jpg', triple)  \n",
        "      if fx >32 and fx <=48 :\n",
        "        if fy <= 16 :\n",
        "          imageio.imsave('TrainingData/8/combine'+  str(filecount) + 'o' +str(entry) + '.jpg', triple)\n",
        "        if fy > 16 and fy <= 32 :\n",
        "          imageio.imsave('TrainingData/9/combine'+ str(filecount) + 'o' + str(entry) + '.jpg', triple)\n",
        "        if fy > 32 and fy <= 48 :\n",
        "          imageio.imsave('TrainingData/10/combine'+  str(filecount) + 'o' +str(entry) + '.jpg', triple)\n",
        "        if fy > 48 and fy <= 64 :\n",
        "          imageio.imsave('TrainingData/11/combine'+ str(filecount) + 'o' + str(entry) + '.jpg', triple)\n",
        "      if fx > 48 and fx <= 64 :\n",
        "        if fy <= 16 :\n",
        "          imageio.imsave('TrainingData/12/combine'+ str(filecount) + 'o' + str(entry) + '.jpg', triple)\n",
        "        if fy > 16 and fy <= 32 :\n",
        "          imageio.imsave('TrainingData/13/combine'+ str(filecount) + 'o' + str(entry) + '.jpg', triple)\n",
        "        if fy > 32 and fy <= 48 :\n",
        "          imageio.imsave('TrainingData/14/combine'+ str(filecount) + 'o' + str(entry) + '.jpg', triple)\n",
        "        if fy > 48 and fy <= 64 :\n",
        "          imageio.imsave('TrainingData/15/combine'+ str(filecount) + 'o' + str(entry) + '.jpg', triple)\n",
        "    \n",
        "      print(entry)\n",
        "      entry = entry + 1"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "rEfhAQ4Ov79i",
        "outputId": "3690f458-4801-4985-bb24-a5df60332c8c"
      },
      "source": [
        "filecount = 0\n",
        "for filename in os.listdir('./Data-Mining-Project/Data/gaze/natural_movies_gaze'):\n",
        "    video_start_index = filename.find('_')+1\n",
        "    video_end_index = filename.find('.coord')\n",
        "    video_path = './Data-Mining-Project/Data/movies_mpg/' + filename[video_start_index: video_end_index] + '.mpg'\n",
        "    maketraindata('./Data-Mining-Project/Data/gaze/natural_movies_gaze/'+filename, video_path, filecount)\n",
        "    filecount = filecount + 1\n",
        "    print(filecount)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "75\n",
            "2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-66b614c67162>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvideo_end_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.coord'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvideo_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./Data-Mining-Project/Data/movies_mpg/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvideo_start_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvideo_end_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.mpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmaketraindata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./Data-Mining-Project/Data/gaze/natural_movies_gaze/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilecount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mfilecount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilecount\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilecount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-c70c36d79414>\u001b[0m in \u001b[0;36mmaketraindata\u001b[0;34m(file, video, filecount)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmaketraindata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilecount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0minterval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintervals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m   \u001b[0mvelocity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvelocities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_saccades\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvelocity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-38e312744804>\u001b[0m in \u001b[0;36mintervals\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m#last = coords[-1][0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mfinal_start_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_loc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosestTime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minterval_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mfinal_end_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_loc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosestTime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-38e312744804>\u001b[0m in \u001b[0;36mclosestTime\u001b[0;34m(coordMatrix, timestamp)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mminim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcoord_matrix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcoordMatrix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoord_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtimestamp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mminim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mminim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoord_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtimestamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mcloseTime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoord_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4H8Nh4m0Mrv_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6642cc4-f668-46ba-9dcf-ff7a5e7045ec"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "trainingdatagen = ImageDataGenerator(validation_split=0.1)\n",
        "traingenerator = trainingdatagen.flow_from_directory('./TrainingData', target_size = (64,192), classes=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15'], batch_size = 20, class_mode = 'categorical')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 114 images belonging to 16 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWlERql8jXL7"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(16, (3,3), padding='same', activation='relu', input_shape=(64, 192, 3)),\n",
        "        tf.keras.layers.MaxPooling2D((2,2),2),\n",
        "        tf.keras.layers.Conv2D(16, (3,3), padding='same', activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2,2),2),\n",
        "        tf.keras.layers.Conv2D(16, (3,3), padding='same', activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2,2),2),\n",
        "        tf.keras.layers.Conv2DTranspose(16, (4,4), padding='same',strides=2, activation='relu'),\n",
        "        tf.keras.layers.Conv2DTranspose(1, (6,6), padding='same',strides=4, activation='sigmoid'),\n",
        "        tf.keras.layers.Conv2D(8, (3,3), padding='same',strides=1, activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2,2),2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(16, activation='softmax')\n",
        "])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwDnZ_J3qmdD",
        "outputId": "3fee36a6-66c1-4d2a-fa5d-c7da1086053e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 64, 192, 16)       448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 32, 96, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 32, 96, 16)        2320      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 16, 48, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 16, 48, 16)        2320      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 8, 24, 16)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 16, 48, 16)        4112      \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTr (None, 64, 192, 1)        577       \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 64, 192, 8)        80        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 32, 96, 8)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 24576)             0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               3145856   \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 16)                2064      \n",
            "=================================================================\n",
            "Total params: 3,157,777\n",
            "Trainable params: 3,157,777\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USQI3HmjqvI0"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "model.compile(optimizer=RMSprop(lr=0.001),loss='categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ax7elJgBq8aJ",
        "outputId": "700e464c-1e63-4529-9563-59261db18ba9"
      },
      "source": [
        "#from tensorflow.keras.optimizers import RMSprop\n",
        "history = model.fit(\n",
        "      traingenerator,\n",
        "      steps_per_epoch=8,  \n",
        "      epochs=15,\n",
        "      verbose=1)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "6/8 [=====================>........] - ETA: 0s - loss: 16.9954 - accuracy: 0.1930WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 120 batches). You may need to use the repeat() function when building your dataset.\n",
            "6/8 [=====================>........] - 2s 266ms/step - loss: 16.9954 - accuracy: 0.1930\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0SQvo_KzwX5",
        "outputId": "70c2de8e-25d5-43f5-8f92-2e0ca4d044a1"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "pretrain_model = tf.keras.applications.VGG16(\n",
        "    include_top=False, weights='imagenet', input_shape=(64, 192, 3), classifier_activation='softmax'\n",
        ")\n",
        "for layer in pretrain_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "last_layer = pretrain_model.get_layer('block5_pool')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)                 \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (16, activation='softmax')(x)           \n",
        "\n",
        "vmodel = Model( pretrain_model.input, x) \n",
        "\n",
        "vmodel.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'categorical_crossentropy', \n",
        "              metrics = ['accuracy'])\n",
        "vmodel.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape:  (None, 2, 6, 512)\n",
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 64, 192, 3)]      0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 64, 192, 64)       1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 64, 192, 64)       36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 32, 96, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 32, 96, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 32, 96, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 16, 48, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 16, 48, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 16, 48, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 16, 48, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 8, 24, 256)        0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 8, 24, 512)        1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 8, 24, 512)        2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 8, 24, 512)        2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 4, 12, 512)        0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 4, 12, 512)        2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 4, 12, 512)        2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 4, 12, 512)        2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 2, 6, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 6144)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1024)              6292480   \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 16)                16400     \n",
            "=================================================================\n",
            "Total params: 21,023,568\n",
            "Trainable params: 6,308,880\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKBuMuRen2AW",
        "outputId": "cff8994f-c3ff-43ee-da6c-b62581d7c5b4"
      },
      "source": [
        "vhistory = vmodel.fit(\n",
        "      traingenerator,\n",
        "      steps_per_epoch=8,  \n",
        "      epochs=15,\n",
        "      verbose=1)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "6/8 [=====================>........] - ETA: 3s - loss: 19.6328 - accuracy: 0.1491WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 120 batches). You may need to use the repeat() function when building your dataset.\n",
            "6/8 [=====================>........] - 11s 2s/step - loss: 19.6328 - accuracy: 0.1491\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsjKj2ewwetr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}